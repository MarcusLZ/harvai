{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we improve our performence by using several retrievers ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n",
      "ERROR - root -  Failed to import 'magic' (from 'python-magic' and 'python-magic-bin' on Windows). FileTypeClassifier will not perform mimetype detection on extensionless files. Please make sure the necessary OS libraries are installed if you need this functionality.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from harvai.bm25 import Bm25\n",
    "from harvai.embedding import Embedding\n",
    "from harvai.nn_model import Nn_model\n",
    "from harvai.dpr import DPR\n",
    "from harvai.utils import score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = Bm25(10)\n",
    "bm25.clean_data()\n",
    "bm25.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'CamembertTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../raw_data/retriever.pt/query_encoder\n",
      "WARNING - haystack.modeling.model.language_model -  Using a model of type 'camembert' which might be incompatible with DPR encoders.Bert based encoders are supported that need input_ids,token_type_ids,attention_mask as input tensors.\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../raw_data/retriever.pt/query_encoder\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'CamembertTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at ../raw_data/retriever.pt/passage_encoder\n",
      "WARNING - haystack.modeling.model.language_model -  Using a model of type 'camembert' which might be incompatible with DPR encoders.Bert based encoders are supported that need input_ids,token_type_ids,attention_mask as input tensors.\n",
      "INFO - haystack.modeling.model.language_model -  Loaded ../raw_data/retriever.pt/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from ../raw_data/retriever.pt\n"
     ]
    }
   ],
   "source": [
    "dpr = DPR(10)\n",
    "dpr.clean_data()\n",
    "dpr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Nn_model(10)\n",
    "nn_model.clean_data()\n",
    "nn_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(10)\n",
    "embedding.clean_data()\n",
    "embedding.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"quelle est la vitesse maximum sur l'autoroute ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.predict(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.predict(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[669, 688, 976, 6, 403]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for article in bm25.articles: \n",
    "    if article in embedding.articles:\n",
    "        output.append(article)\n",
    "\n",
    "if len(output) == 0: \n",
    "    output = bm25.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[669, 688, 976, 6, 403]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixRetriever: \n",
    "    def __init__(self,retriever1,retriever2):\n",
    "        self.retriever1 = retriever1\n",
    "        self.retriever2 = retriever2\n",
    "        self.articles = None\n",
    "    \n",
    "    def predict(self,question):\n",
    "        self.retriever1.predict(question)\n",
    "        self.retriever2.predict(question)\n",
    "     \n",
    "        output =[]\n",
    "        for article in self.retriever1.articles: \n",
    "            if article in self.retriever2.articles:\n",
    "                output.append(article)\n",
    "\n",
    "        if len(output) == 0: \n",
    "            output = self.retriever1.articles\n",
    "\n",
    "        self.articles = output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_mutant = MixRetriever(dpr,bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:09<00:00,  5.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall': 0.5294117647058824, 'average rank': 1.4074074074074074}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(retriever_mutant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 226.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall': 0.8235294117647058, 'average rank': 2.1666666666666665}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0f25c9bd0470a19455c7c824ec10a56b8965329568d5279379e9f6655b5cebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
